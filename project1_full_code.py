# -*- coding: utf-8 -*-
"""Project1_full code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MedccGKETws22QTYTa-cQBBWYfxW_j3p
"""

import pandas as pd
import numpy as np
from google.colab import drive

from pandas import read_excel

# Load the dataset
drive.mount('/content/drive')

df = pd.read_excel('/content/drive/My Drive/Interbankrates.xlsx')
#we display the first rows of data and confirm we have the right dataset
df.head()
df.tail()

#we get some basic information about the dataset
df.info()

# we get descriptive statistics about the data
df.describe()

#plot line graph
df.plot(figsize=(12,6))

"""Data Cleaning"""

#we check for missing values
df.isnull().sum()

# we wont check for duplicates because daily interbank rates are close to each other
#plot a histogram
df.hist(bins=50, figsize=(20,15))

#drop the first column
data = df.drop(df.columns[0], axis=1)
data.head()

data.shape

#pre process the time series for LSTM
#fit an LSTM model
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)
scaled_data.shape

#create time series sequence
time_step = 20
#X, y = create_sequences(scaled_data, time_step)
X = []
y = []
for i in range(len(scaled_data)-time_step):
    X.append(scaled_data[i:i+time_step])
    y.append(scaled_data[i+time_step])

#reshaping for LSTM
X = np.array(X)
y = np.array(y)
#
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split data into training and testing sets (80% train, 20% test)
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]
X_train.shape
X_test.shape

#Build LSTM model
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.layers import Dropout
from keras.callbacks import EarlyStopping

# Build LSTM model
model = Sequential()
model.add(LSTM(20, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))  # Regularization to prevent overfitting
model.add(LSTM(20, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))
#Define output layer of LSTM

# Compile model
model.compile(optimizer='adam', loss='mean_squared_error')

# Early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Train the model
model.fit(X_train, y_train, epochs=200, batch_size=10, validation_data=(X_test, y_test), callbacks=[early_stopping])
#model.fit(X_train, y_train, epochs=200, batch_size=10, validation_data=(X_test, y_test), callbacks=[early_stopping])
# Evaluate the model
train_loss = model.evaluate(X_train, y_train, verbose=0)
test_loss = model.evaluate(X_test, y_test, verbose=0)
print(f'Train Loss: {train_loss}, Test Loss: {test_loss}')

#reshape output
predict=model.predict(X_test)

#scale back prdiction
predict = scaler.inverse_transform(predict)
#

print("y_test:", y_test.shape, "y_pred:", predict.shape)
#make prediction with model
#print prediction next 10 values
print(predict[:10])
print(predict)

#check accuracy of model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
from math import sqrt

# Calculate accuracy metrics
# make y have the same number of output as predict
y = y[:len(predict)]


rmse= sqrt(mean_squared_error(y_test, predict))
mae = mean_absolute_error(y_test, predict)
r2 = r2_score(y_test, predict)

print(f'RMSE: {rmse}, MAE: {mae}, R2: {r2}')

